Nvidia-Triton
This repository provides scripts and examples to facilitate model export to ONNX format for use with ONNX Runtime. It also includes tools for running benchmarks on Nvidia Triton Inference Server. The repository includes example client code, benchmark results, and reports for testing on Nvidia A30 GPUs.


Reports:


Results:

e5-multilingual-base   
![Alt text](./reports/A30/results-e5-multilingual-base.png)

e5-large 
![Alt text](./reports/A30/results-e5-large.png)

e5-large-mixed
![Alt text](./reports/A30/results-e5-large-mixed.png)

e5-large-fp16
![Alt text](./reports/A30/results-e5-large-mixed.png)




 






